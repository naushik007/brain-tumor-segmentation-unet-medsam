{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0b7c7d5d",
      "metadata": {},
      "source": [
        "## üéâ Complete!\n",
        "\n",
        "You now have a full brain tumor segmentation pipeline with:\n",
        "\n",
        "‚úÖ **Data loading & preprocessing** with MONAI transforms  \n",
        "‚úÖ **3D U-Net model** with ~31M parameters  \n",
        "‚úÖ **Training loop** with mixed precision & checkpointing  \n",
        "‚úÖ **Evaluation metrics** (WT, TC, ET Dice scores)  \n",
        "‚úÖ **Visualization** of predictions  \n",
        "‚úÖ **Failure analysis** for debugging  \n",
        "‚úÖ **Experiment tracking** for comparison  \n",
        "\n",
        "### Next Steps:\n",
        "1. **Hyperparameter tuning**: Try different learning rates, batch sizes, loss weights\n",
        "2. **Advanced augmentation**: Add more data augmentation techniques\n",
        "3. **Ensemble methods**: Combine multiple models for better performance\n",
        "4. **Post-processing**: Add CRF or morphological operations\n",
        "5. **MedSAM fine-tuning**: Experiment with foundation models\n",
        "\n",
        "### Key Metrics to Report:\n",
        "- **Whole Tumor (WT) Dice**: Overall tumor detection\n",
        "- **Tumor Core (TC) Dice**: Core tumor regions\n",
        "- **Enhancing Tumor (ET) Dice**: Active tumor areas\n",
        "\n",
        "Good luck with your project! üöÄ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "985f814d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Uncomment to install and use MedSAM\n",
        "# !pip install git+https://github.com/bowang-lab/MedSAM.git\n",
        "# !wget https://github.com/bowang-lab/MedSAM/releases/download/v0.1/medsam_vit_b.pth\n",
        "\n",
        "# from segment_anything import sam_model_registry\n",
        "\n",
        "# class MedSAMFineTune(nn.Module):\n",
        "#     \"\"\"MedSAM with frozen encoder for brain tumor segmentation\"\"\"\n",
        "    \n",
        "#     def __init__(self, checkpoint_path, num_classes=4):\n",
        "#         super().__init__()\n",
        "#         self.medsam = sam_model_registry[\"vit_b\"](checkpoint=checkpoint_path)\n",
        "        \n",
        "#         # Freeze encoder\n",
        "#         for param in self.medsam.image_encoder.parameters():\n",
        "#             param.requires_grad = False\n",
        "        \n",
        "#         # Custom segmentation head\n",
        "#         self.seg_head = nn.Sequential(\n",
        "#             nn.Conv2d(256, 128, 3, padding=1),\n",
        "#             nn.BatchNorm2d(128),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Conv2d(128, num_classes, 1)\n",
        "#         )\n",
        "    \n",
        "#     def forward(self, x):\n",
        "#         \"\"\"Process 3D volume slice by slice\"\"\"\n",
        "#         B, C, H, W, D = x.shape\n",
        "#         outputs = []\n",
        "#         for d in range(D):\n",
        "#             # Convert to 3-channel for SAM\n",
        "#             slice_x = x[:, :, :, :, d].mean(dim=1, keepdim=True).repeat(1, 3, 1, 1)\n",
        "#             features = self.medsam.image_encoder(slice_x)\n",
        "#             outputs.append(self.seg_head(features))\n",
        "#         return torch.stack(outputs, dim=-1)\n",
        "\n",
        "# # Create MedSAM model\n",
        "# medsam_model = MedSAMFineTune('medsam_vit_b.pth', num_classes=4).to(device)\n",
        "# print(\"‚úÖ MedSAM model created with frozen encoder\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e73a2f64",
      "metadata": {},
      "source": [
        "## 16. (BONUS) MedSAM Fine-tuning Setup\n",
        "\n",
        "**Note**: This section shows how to fine-tune MedSAM for brain tumor segmentation. Uncomment and run if you want to experiment with foundation models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cd448e7",
      "metadata": {},
      "outputs": [],
      "source": [
        "class ExperimentTracker:\n",
        "    \"\"\"Simple experiment tracking class\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.experiments = {}\n",
        "    \n",
        "    def log(self, name, config, results):\n",
        "        \"\"\"Log an experiment\"\"\"\n",
        "        self.experiments[name] = {\n",
        "            'config': config,\n",
        "            'results': results\n",
        "        }\n",
        "        print(f\"‚úÖ Logged experiment: {name}\")\n",
        "    \n",
        "    def compare(self):\n",
        "        \"\"\"Compare all experiments\"\"\"\n",
        "        print(\"\\n\" + \"=\"*90)\n",
        "        print(\"üìä EXPERIMENT COMPARISON\")\n",
        "        print(\"=\"*90)\n",
        "        \n",
        "        for name, exp in self.experiments.items():\n",
        "            print(f\"\\n{name}:\")\n",
        "            print(f\"  Config: {exp['config']}\")\n",
        "            print(f\"  Results:\")\n",
        "            for k, v in exp['results'].items():\n",
        "                if isinstance(v, float):\n",
        "                    print(f\"    {k}: {v:.4f}\")\n",
        "                else:\n",
        "                    print(f\"    {k}: {v}\")\n",
        "        print(\"=\"*90)\n",
        "    \n",
        "    def save(self, filepath):\n",
        "        \"\"\"Save experiments to JSON\"\"\"\n",
        "        with open(filepath, 'w') as f:\n",
        "            json.dump(self.experiments, f, indent=2)\n",
        "        print(f\"üíæ Saved experiments to {filepath}\")\n",
        "\n",
        "# Create tracker and log current experiment\n",
        "tracker = ExperimentTracker()\n",
        "\n",
        "tracker.log(\n",
        "    name='3D_UNet_DiceCE_v1',\n",
        "    config={\n",
        "        'model': '3D U-Net',\n",
        "        'loss': 'DiceCE (0.5/0.5)',\n",
        "        'optimizer': 'AdamW',\n",
        "        'lr': 1e-4,\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'epochs': NUM_EPOCHS,\n",
        "        'augmentation': 'Yes'\n",
        "    },\n",
        "    results=test_results\n",
        ")\n",
        "\n",
        "tracker.compare()\n",
        "\n",
        "# Save experiments\n",
        "tracker.save(os.path.join(SAVE_DIR, 'experiments.json'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "846dc76c",
      "metadata": {},
      "source": [
        "## 15. Experiment Tracking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38e6a3ee",
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_failures(model, test_loader, device):\n",
        "    \"\"\"Analyze failure cases\"\"\"\n",
        "    model.eval()\n",
        "    cases = []\n",
        "    \n",
        "    print(\"Analyzing all test cases...\")\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for idx, batch_data in enumerate(test_loader):\n",
        "            inputs = batch_data[\"image\"].to(device)\n",
        "            labels = batch_data[\"label\"].to(device)\n",
        "            \n",
        "            outputs = sliding_window_inference(\n",
        "                inputs, \n",
        "                roi_size=(128, 128, 128),\n",
        "                sw_batch_size=4, \n",
        "                predictor=model\n",
        "            )\n",
        "            preds = torch.argmax(outputs, dim=1, keepdim=True)\n",
        "            \n",
        "            metrics = compute_region_metrics(preds[0, 0], labels[0, 0])\n",
        "            \n",
        "            cases.append({\n",
        "                'id': idx,\n",
        "                'dice_wt': metrics['dice_wt'],\n",
        "                'dice_tc': metrics['dice_tc'],\n",
        "                'dice_et': metrics['dice_et'],\n",
        "                'mean': np.mean(list(metrics.values()))\n",
        "            })\n",
        "    \n",
        "    # Sort by mean Dice score\n",
        "    cases_sorted = sorted(cases, key=lambda x: x['mean'])\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üî¥ WORST 10 CASES (Lowest Dice Scores)\")\n",
        "    print(\"=\"*70)\n",
        "    for i, case in enumerate(cases_sorted[:10]):\n",
        "        print(f\"{i+1:2d}. Case {case['id']:3d}: Mean={case['mean']:.4f} | \"\n",
        "              f\"WT={case['dice_wt']:.4f}, TC={case['dice_tc']:.4f}, ET={case['dice_et']:.4f}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üü¢ BEST 10 CASES (Highest Dice Scores)\")\n",
        "    print(\"=\"*70)\n",
        "    for i, case in enumerate(cases_sorted[-10:][::-1]):\n",
        "        print(f\"{i+1:2d}. Case {case['id']:3d}: Mean={case['mean']:.4f} | \"\n",
        "              f\"WT={case['dice_wt']:.4f}, TC={case['dice_tc']:.4f}, ET={case['dice_et']:.4f}\")\n",
        "    \n",
        "    return cases_sorted\n",
        "\n",
        "# Perform failure analysis\n",
        "failure_cases = analyze_failures(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77da3119",
      "metadata": {},
      "source": [
        "## 14. Failure Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37b909e4",
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_predictions(model, test_loader, device, n_samples=5):\n",
        "    \"\"\"Visualize model predictions\"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    fig, axes = plt.subplots(n_samples, 4, figsize=(16, n_samples*4))\n",
        "    if n_samples == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for idx, batch_data in enumerate(test_loader):\n",
        "            if idx >= n_samples:\n",
        "                break\n",
        "            \n",
        "            inputs = batch_data[\"image\"].to(device)\n",
        "            labels = batch_data[\"label\"].to(device)\n",
        "            \n",
        "            # Get predictions\n",
        "            outputs = sliding_window_inference(\n",
        "                inputs, \n",
        "                roi_size=(128, 128, 128),\n",
        "                sw_batch_size=4, \n",
        "                predictor=model\n",
        "            )\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            \n",
        "            # Get middle slice\n",
        "            z = inputs.shape[-1] // 2\n",
        "            \n",
        "            # FLAIR modality\n",
        "            axes[idx, 0].imshow(inputs[0, 0, :, :, z].cpu(), cmap='gray')\n",
        "            axes[idx, 0].set_title('FLAIR', fontsize=12, fontweight='bold')\n",
        "            axes[idx, 0].axis('off')\n",
        "            \n",
        "            # T1ce modality\n",
        "            axes[idx, 1].imshow(inputs[0, 1, :, :, z].cpu(), cmap='gray')\n",
        "            axes[idx, 1].set_title('T1ce', fontsize=12, fontweight='bold')\n",
        "            axes[idx, 1].axis('off')\n",
        "            \n",
        "            # Ground truth\n",
        "            axes[idx, 2].imshow(labels[0, 0, :, :, z].cpu(), cmap='jet', vmin=0, vmax=3)\n",
        "            axes[idx, 2].set_title('Ground Truth', fontsize=12, fontweight='bold')\n",
        "            axes[idx, 2].axis('off')\n",
        "            \n",
        "            # Prediction\n",
        "            axes[idx, 3].imshow(preds[0, :, :, z].cpu(), cmap='jet', vmin=0, vmax=3)\n",
        "            \n",
        "            # Calculate Dice for this sample\n",
        "            metrics = compute_region_metrics(preds[0], labels[0, 0])\n",
        "            mean_dice = np.mean(list(metrics.values()))\n",
        "            axes[idx, 3].set_title(f'Prediction (Dice: {mean_dice:.3f})', \n",
        "                                   fontsize=12, fontweight='bold')\n",
        "            axes[idx, 3].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(SAVE_DIR, 'predictions_visualization.png'), \n",
        "                dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "# Visualize predictions\n",
        "visualize_predictions(model, test_loader, device, n_samples=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66b21e9a",
      "metadata": {},
      "source": [
        "## 13. Visualize Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a268fade",
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_test_set(model, test_loader, device, model_path):\n",
        "    \"\"\"Evaluate model on test set\"\"\"\n",
        "    \n",
        "    # Load best model\n",
        "    checkpoint = torch.load(model_path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.eval()\n",
        "    \n",
        "    print(f\"Loaded model from epoch {checkpoint['epoch']} with Dice: {checkpoint['best_dice']:.4f}\")\n",
        "    \n",
        "    all_metrics = {'dice_wt': [], 'dice_tc': [], 'dice_et': []}\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for idx, batch_data in enumerate(test_loader):\n",
        "            inputs = batch_data[\"image\"].to(device)\n",
        "            labels = batch_data[\"label\"].to(device)\n",
        "            \n",
        "            # Sliding window inference\n",
        "            outputs = sliding_window_inference(\n",
        "                inputs, \n",
        "                roi_size=(128, 128, 128),\n",
        "                sw_batch_size=4, \n",
        "                predictor=model\n",
        "            )\n",
        "            \n",
        "            preds = torch.argmax(outputs, dim=1, keepdim=True)\n",
        "            metrics = compute_region_metrics(preds[0, 0], labels[0, 0])\n",
        "            \n",
        "            for k, v in metrics.items():\n",
        "                all_metrics[k].append(v)\n",
        "            \n",
        "            if (idx + 1) % 10 == 0:\n",
        "                print(f\"  Evaluated {idx + 1}/{len(test_loader)} samples\")\n",
        "    \n",
        "    # Calculate statistics\n",
        "    results = {}\n",
        "    for k, v in all_metrics.items():\n",
        "        results[f'{k}_mean'] = np.mean(v)\n",
        "        results[f'{k}_std'] = np.std(v)\n",
        "        results[f'{k}_median'] = np.median(v)\n",
        "    \n",
        "    # Print results\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üìä TEST SET RESULTS\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"WT (Whole Tumor):    {results['dice_wt_mean']:.4f} ¬± {results['dice_wt_std']:.4f}\")\n",
        "    print(f\"TC (Tumor Core):     {results['dice_tc_mean']:.4f} ¬± {results['dice_tc_std']:.4f}\")\n",
        "    print(f\"ET (Enhancing):      {results['dice_et_mean']:.4f} ¬± {results['dice_et_std']:.4f}\")\n",
        "    print(f\"Mean Dice:           {np.mean([results['dice_wt_mean'], results['dice_tc_mean'], results['dice_et_mean']]):.4f}\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    return results, all_metrics\n",
        "\n",
        "# Evaluate on test set\n",
        "test_results, test_metrics_all = evaluate_test_set(model, test_loader, device, best_model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a72c7da",
      "metadata": {},
      "source": [
        "## 12. Test Set Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a577b0e9",
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_training_curves(history):\n",
        "    \"\"\"Plot training curves\"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "    \n",
        "    # Loss curves\n",
        "    axes[0].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
        "    axes[0].plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
        "    axes[0].set_xlabel('Epoch', fontsize=12)\n",
        "    axes[0].set_ylabel('Loss', fontsize=12)\n",
        "    axes[0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
        "    axes[0].legend(fontsize=11)\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Dice score curves\n",
        "    axes[1].plot(history['dice_wt'], label='WT (Whole Tumor)', linewidth=2)\n",
        "    axes[1].plot(history['dice_tc'], label='TC (Tumor Core)', linewidth=2)\n",
        "    axes[1].plot(history['dice_et'], label='ET (Enhancing)', linewidth=2)\n",
        "    axes[1].plot(history['mean_dice'], label='Mean Dice', linewidth=2, linestyle='--', color='black')\n",
        "    axes[1].set_xlabel('Epoch', fontsize=12)\n",
        "    axes[1].set_ylabel('Dice Score', fontsize=12)\n",
        "    axes[1].set_title('Validation Dice Scores', fontsize=14, fontweight='bold')\n",
        "    axes[1].legend(fontsize=11)\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "    axes[1].set_ylim([0, 1])\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(SAVE_DIR, 'training_curves.png'), dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "plot_training_curves(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "628ee7e0",
      "metadata": {},
      "source": [
        "## 11. Visualize Training Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5d074f9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training configuration\n",
        "NUM_EPOCHS = 100\n",
        "best_dice = 0\n",
        "best_epoch = 0\n",
        "\n",
        "# Paths for saving models\n",
        "best_model_path = os.path.join(SAVE_DIR, \"best_3d_unet.pth\")\n",
        "last_model_path = os.path.join(SAVE_DIR, \"last_3d_unet.pth\")\n",
        "\n",
        "# Training history\n",
        "history = {\n",
        "    'train_loss': [],\n",
        "    'val_loss': [],\n",
        "    'dice_wt': [],\n",
        "    'dice_tc': [],\n",
        "    'dice_et': [],\n",
        "    'mean_dice': []\n",
        "}\n",
        "\n",
        "print(f\"üöÄ Starting training for {NUM_EPOCHS} epochs...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "    print(\"-\" * 70)\n",
        "    \n",
        "    # Train\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, loss_function, scaler, device)\n",
        "    \n",
        "    # Validate\n",
        "    val_loss, metrics = validate(model, val_loader, loss_function, device)\n",
        "    \n",
        "    # Update learning rate\n",
        "    scheduler.step()\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "    \n",
        "    # Calculate mean Dice score\n",
        "    mean_dice = np.mean(list(metrics.values()))\n",
        "    \n",
        "    # Update history\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['dice_wt'].append(metrics['dice_wt'])\n",
        "    history['dice_tc'].append(metrics['dice_tc'])\n",
        "    history['dice_et'].append(metrics['dice_et'])\n",
        "    history['mean_dice'].append(mean_dice)\n",
        "    \n",
        "    # Print epoch summary\n",
        "    print(f\"\\nüìä Epoch {epoch+1} Summary:\")\n",
        "    print(f\"   Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | LR: {current_lr:.6f}\")\n",
        "    print(f\"   Dice WT: {metrics['dice_wt']:.4f} | TC: {metrics['dice_tc']:.4f} | ET: {metrics['dice_et']:.4f}\")\n",
        "    print(f\"   Mean Dice: {mean_dice:.4f}\")\n",
        "    \n",
        "    # Save best model\n",
        "    if mean_dice > best_dice:\n",
        "        best_dice = mean_dice\n",
        "        best_epoch = epoch + 1\n",
        "        torch.save({\n",
        "            'epoch': epoch + 1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'best_dice': best_dice,\n",
        "            'metrics': metrics\n",
        "        }, best_model_path)\n",
        "        print(f\"   ‚úÖ New best model saved! (Dice: {best_dice:.4f})\")\n",
        "    \n",
        "    # Save last model\n",
        "    torch.save({\n",
        "        'epoch': epoch + 1,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'scheduler_state_dict': scheduler.state_dict(),\n",
        "        'history': history\n",
        "    }, last_model_path)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"‚úÖ Training completed!\")\n",
        "print(f\"   Best Dice: {best_dice:.4f} at epoch {best_epoch}\")\n",
        "print(f\"   Models saved to: {SAVE_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28eb6d6b",
      "metadata": {},
      "source": [
        "## 10. Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22c6ed96",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_epoch(model, train_loader, optimizer, loss_function, scaler, device):\n",
        "    \"\"\"Train for one epoch\"\"\"\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for batch_idx, batch_data in enumerate(train_loader):\n",
        "        inputs = batch_data[\"image\"].to(device)\n",
        "        labels = batch_data[\"label\"].to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Mixed precision training\n",
        "        with autocast():\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_function(outputs, labels)\n",
        "        \n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "        if (batch_idx + 1) % 10 == 0:\n",
        "            print(f\"  Batch {batch_idx + 1}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
        "    \n",
        "    return epoch_loss / len(train_loader)\n",
        "\n",
        "def validate(model, val_loader, loss_function, device):\n",
        "    \"\"\"Validate model\"\"\"\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    all_metrics = {'dice_wt': [], 'dice_tc': [], 'dice_et': []}\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_data in val_loader:\n",
        "            inputs = batch_data[\"image\"].to(device)\n",
        "            labels = batch_data[\"label\"].to(device)\n",
        "            \n",
        "            # Use sliding window inference for better predictions\n",
        "            outputs = sliding_window_inference(\n",
        "                inputs, \n",
        "                roi_size=(128, 128, 128),\n",
        "                sw_batch_size=4, \n",
        "                predictor=model\n",
        "            )\n",
        "            \n",
        "            val_loss += loss_function(outputs, labels).item()\n",
        "            \n",
        "            # Get predictions\n",
        "            preds = torch.argmax(outputs, dim=1, keepdim=True)\n",
        "            \n",
        "            # Compute metrics\n",
        "            metrics = compute_region_metrics(preds[0, 0], labels[0, 0])\n",
        "            for k, v in metrics.items():\n",
        "                all_metrics[k].append(v)\n",
        "    \n",
        "    # Average metrics\n",
        "    avg_metrics = {k: np.mean(v) for k, v in all_metrics.items()}\n",
        "    avg_loss = val_loss / len(val_loader)\n",
        "    \n",
        "    return avg_loss, avg_metrics\n",
        "\n",
        "print(\"‚úÖ Training and validation functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64ca05b8",
      "metadata": {},
      "source": [
        "## 9. Training & Validation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe457d90",
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_region_metrics(pred, label):\n",
        "    \"\"\"\n",
        "    Compute Dice scores for BraTS tumor regions:\n",
        "    - WT (Whole Tumor): All tumor classes (1, 2, 3)\n",
        "    - TC (Tumor Core): Labels 1 and 3\n",
        "    - ET (Enhancing Tumor): Label 3 only\n",
        "    \n",
        "    Args:\n",
        "        pred: Predicted segmentation (H, W, D)\n",
        "        label: Ground truth segmentation (H, W, D)\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with Dice scores for each region\n",
        "    \"\"\"\n",
        "    pred_np = pred.cpu().numpy()\n",
        "    label_np = label.cpu().numpy()\n",
        "    \n",
        "    # Whole Tumor (all non-zero labels)\n",
        "    wt_pred = (pred_np > 0).astype(np.float32)\n",
        "    wt_label = (label_np > 0).astype(np.float32)\n",
        "    \n",
        "    # Tumor Core (labels 1 and 3)\n",
        "    tc_pred = ((pred_np == 1) | (pred_np == 3)).astype(np.float32)\n",
        "    tc_label = ((label_np == 1) | (label_np == 3)).astype(np.float32)\n",
        "    \n",
        "    # Enhancing Tumor (label 3 only)\n",
        "    et_pred = (pred_np == 3).astype(np.float32)\n",
        "    et_label = (label_np == 3).astype(np.float32)\n",
        "    \n",
        "    def dice_score(pred, label):\n",
        "        \"\"\"Calculate Dice coefficient\"\"\"\n",
        "        smooth = 1e-5\n",
        "        intersection = np.sum(pred * label)\n",
        "        union = np.sum(pred) + np.sum(label)\n",
        "        return (2.0 * intersection + smooth) / (union + smooth)\n",
        "    \n",
        "    return {\n",
        "        'dice_wt': dice_score(wt_pred, wt_label),\n",
        "        'dice_tc': dice_score(tc_pred, tc_label),\n",
        "        'dice_et': dice_score(et_pred, et_label)\n",
        "    }\n",
        "\n",
        "print(\"‚úÖ Evaluation metrics defined\")\n",
        "print(\"   - WT (Whole Tumor): All tumor classes\")\n",
        "print(\"   - TC (Tumor Core): Necrotic + Enhancing\")\n",
        "print(\"   - ET (Enhancing Tumor): Enhancing only\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d751507",
      "metadata": {},
      "source": [
        "## 8. Evaluation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b796dec",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loss function: Dice + Cross Entropy\n",
        "loss_function = DiceCELoss(\n",
        "    include_background=False,  # Don't include background class\n",
        "    to_onehot_y=True,           # Convert labels to one-hot\n",
        "    softmax=True,               # Apply softmax to predictions\n",
        "    lambda_dice=0.5,            # Weight for Dice loss\n",
        "    lambda_ce=0.5               # Weight for Cross Entropy loss\n",
        ")\n",
        "\n",
        "# Optimizer: AdamW with weight decay\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(), \n",
        "    lr=1e-4, \n",
        "    weight_decay=1e-5\n",
        ")\n",
        "\n",
        "# Learning rate scheduler: Cosine annealing\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "    optimizer, \n",
        "    T_max=100\n",
        ")\n",
        "\n",
        "# Mixed precision training scaler\n",
        "scaler = GradScaler()\n",
        "\n",
        "print(\"‚úÖ Training components initialized\")\n",
        "print(f\"   - Loss: Dice + Cross Entropy (50/50)\")\n",
        "print(f\"   - Optimizer: AdamW (lr=1e-4, wd=1e-5)\")\n",
        "print(f\"   - Scheduler: CosineAnnealingLR\")\n",
        "print(f\"   - Mixed precision: Enabled\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "782bb9ba",
      "metadata": {},
      "source": [
        "## 7. Loss Function, Optimizer & Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bd8f5fe",
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_3d_unet(in_channels=4, out_channels=4):\n",
        "    \"\"\"\n",
        "    Create 3D U-Net model for brain tumor segmentation\n",
        "    \n",
        "    Args:\n",
        "        in_channels: Number of input modalities (FLAIR, T1ce, T1, T2)\n",
        "        out_channels: Number of output classes (background, necrotic, edema, enhancing)\n",
        "    \n",
        "    Returns:\n",
        "        MONAI UNet model\n",
        "    \"\"\"\n",
        "    model = UNet(\n",
        "        spatial_dims=3,\n",
        "        in_channels=in_channels,\n",
        "        out_channels=out_channels,\n",
        "        channels=(32, 64, 128, 256, 512),\n",
        "        strides=(2, 2, 2, 2),\n",
        "        num_res_units=2,\n",
        "        dropout=0.1\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Create model\n",
        "model = create_3d_unet(in_channels=4, out_channels=4).to(device)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"‚úÖ 3D U-Net model created\")\n",
        "print(f\"   - Total parameters: {total_params:,}\")\n",
        "print(f\"   - Trainable parameters: {trainable_params:,}\")\n",
        "print(f\"   - Model size: ~{total_params * 4 / 1024**2:.1f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb0310c7",
      "metadata": {},
      "source": [
        "## 6. Model Architecture - 3D U-Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23081b13",
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_dataloaders(train_files, val_files, test_files, \n",
        "                       train_transforms, val_transforms, test_transforms,\n",
        "                       batch_size=2, cache_rate=1.0):\n",
        "    \"\"\"\n",
        "    Create MONAI DataLoaders with caching for faster training\n",
        "    \n",
        "    Args:\n",
        "        train_files, val_files, test_files: List of data dictionaries\n",
        "        train_transforms, val_transforms, test_transforms: MONAI transform objects\n",
        "        batch_size: Batch size for training\n",
        "        cache_rate: Fraction of data to cache in memory (1.0 = all data)\n",
        "    \n",
        "    Returns:\n",
        "        train_loader, val_loader, test_loader\n",
        "    \"\"\"\n",
        "    \n",
        "    # Create cached datasets for faster loading\n",
        "    train_ds = CacheDataset(\n",
        "        data=train_files, \n",
        "        transform=train_transforms, \n",
        "        cache_rate=cache_rate, \n",
        "        num_workers=4\n",
        "    )\n",
        "    \n",
        "    val_ds = CacheDataset(\n",
        "        data=val_files, \n",
        "        transform=val_transforms, \n",
        "        cache_rate=cache_rate, \n",
        "        num_workers=4\n",
        "    )\n",
        "    \n",
        "    test_ds = CacheDataset(\n",
        "        data=test_files, \n",
        "        transform=test_transforms, \n",
        "        cache_rate=cache_rate, \n",
        "        num_workers=4\n",
        "    )\n",
        "    \n",
        "    # Create data loaders\n",
        "    train_loader = MonaiDataLoader(\n",
        "        train_ds, \n",
        "        batch_size=batch_size, \n",
        "        shuffle=True, \n",
        "        num_workers=0,\n",
        "        pin_memory=torch.cuda.is_available()\n",
        "    )\n",
        "    \n",
        "    val_loader = MonaiDataLoader(\n",
        "        val_ds, \n",
        "        batch_size=1, \n",
        "        shuffle=False, \n",
        "        num_workers=0,\n",
        "        pin_memory=torch.cuda.is_available()\n",
        "    )\n",
        "    \n",
        "    test_loader = MonaiDataLoader(\n",
        "        test_ds, \n",
        "        batch_size=1, \n",
        "        shuffle=False, \n",
        "        num_workers=0,\n",
        "        pin_memory=torch.cuda.is_available()\n",
        "    )\n",
        "    \n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "# Create data loaders\n",
        "BATCH_SIZE = 2\n",
        "train_loader, val_loader, test_loader = create_dataloaders(\n",
        "    train_files, val_files, test_files,\n",
        "    train_transforms, val_transforms, test_transforms, \n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ DataLoaders created successfully\")\n",
        "print(f\"   - Train batches: {len(train_loader)} (batch size: {BATCH_SIZE})\")\n",
        "print(f\"   - Val batches: {len(val_loader)} (batch size: 1)\")\n",
        "print(f\"   - Test batches: {len(test_loader)} (batch size: 1)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61b24062",
      "metadata": {},
      "source": [
        "## 5. Create DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "328cfa21",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_preprocessing_transforms(mode='train'):\n",
        "    \"\"\"\n",
        "    Get preprocessing transforms for training, validation, or testing\n",
        "    \n",
        "    Args:\n",
        "        mode: 'train', 'val', or 'test'\n",
        "    \n",
        "    Returns:\n",
        "        MONAI Compose object with transforms\n",
        "    \"\"\"\n",
        "    \n",
        "    # Common transforms for all modes\n",
        "    common_transforms = [\n",
        "        LoadImaged(keys=[\"image\", \"label\"]),\n",
        "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
        "        Spacingd(keys=[\"image\", \"label\"], pixdim=(1.0, 1.0, 1.0), \n",
        "                mode=(\"bilinear\", \"nearest\")),\n",
        "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\", margin=10),\n",
        "        ResizeWithPadOrCropd(keys=[\"image\", \"label\"], spatial_size=(128, 128, 128)),\n",
        "        NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
        "    ]\n",
        "    \n",
        "    # Add augmentation transforms for training only\n",
        "    if mode == 'train':\n",
        "        train_transforms = common_transforms + [\n",
        "            RandRotate90d(keys=[\"image\", \"label\"], prob=0.5, spatial_axes=(0, 1)),\n",
        "            RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
        "            RandScaleIntensityd(keys=\"image\", factors=0.1, prob=0.5),\n",
        "            RandShiftIntensityd(keys=\"image\", offsets=0.1, prob=0.5),\n",
        "        ]\n",
        "        return Compose(train_transforms)\n",
        "    \n",
        "    return Compose(common_transforms)\n",
        "\n",
        "# Create transforms for each dataset split\n",
        "train_transforms = get_preprocessing_transforms(mode='train')\n",
        "val_transforms = get_preprocessing_transforms(mode='val')\n",
        "test_transforms = get_preprocessing_transforms(mode='test')\n",
        "\n",
        "print(\"‚úÖ Preprocessing transforms created\")\n",
        "print(f\"   - Training: {len(train_transforms.transforms)} transforms (with augmentation)\")\n",
        "print(f\"   - Validation: {len(val_transforms.transforms)} transforms\")\n",
        "print(f\"   - Test: {len(test_transforms.transforms)} transforms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05436f20",
      "metadata": {},
      "source": [
        "## 4. Preprocessing Transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "625d6d40",
      "metadata": {},
      "outputs": [],
      "source": [
        "class MSDDatasetPreparation:\n",
        "    \"\"\"Dataset preparation class for MSD Task01_BrainTumour\"\"\"\n",
        "    \n",
        "    def __init__(self, data_root, train_ratio=0.7, val_ratio=0.15):\n",
        "        self.data_root = Path(data_root)\n",
        "        self.train_ratio = train_ratio\n",
        "        self.val_ratio = val_ratio\n",
        "        \n",
        "    def load_dataset_json(self):\n",
        "        \"\"\"Load dataset.json metadata\"\"\"\n",
        "        json_path = self.data_root / \"dataset.json\"\n",
        "        with open(json_path, 'r') as f:\n",
        "            dataset_info = json.load(f)\n",
        "        return dataset_info\n",
        "    \n",
        "    def prepare_data_dicts(self):\n",
        "        \"\"\"Prepare data dictionaries with image and label paths\"\"\"\n",
        "        dataset_info = self.load_dataset_json()\n",
        "        data_dicts = []\n",
        "        \n",
        "        for item in dataset_info['training']:\n",
        "            # Convert relative paths to absolute paths\n",
        "            image_path = str(self.data_root / item['image'].lstrip('./'))\n",
        "            label_path = str(self.data_root / item['label'].lstrip('./'))\n",
        "            \n",
        "            data_dicts.append({\n",
        "                'image': image_path,\n",
        "                'label': label_path\n",
        "            })\n",
        "        \n",
        "        return data_dicts, dataset_info\n",
        "    \n",
        "    def split_dataset(self, data_dicts, seed=42):\n",
        "        \"\"\"Split dataset into train, validation, and test sets\"\"\"\n",
        "        np.random.seed(seed)\n",
        "        n_total = len(data_dicts)\n",
        "        indices = np.random.permutation(n_total)\n",
        "        \n",
        "        n_train = int(n_total * self.train_ratio)\n",
        "        n_val = int(n_total * self.val_ratio)\n",
        "        \n",
        "        train_files = [data_dicts[i] for i in indices[:n_train]]\n",
        "        val_files = [data_dicts[i] for i in indices[n_train:n_train+n_val]]\n",
        "        test_files = [data_dicts[i] for i in indices[n_train+n_val:]]\n",
        "        \n",
        "        print(f\"Dataset split:\")\n",
        "        print(f\"  Train: {len(train_files)} samples ({self.train_ratio*100:.0f}%)\")\n",
        "        print(f\"  Val: {len(val_files)} samples ({self.val_ratio*100:.0f}%)\")\n",
        "        print(f\"  Test: {len(test_files)} samples ({(1-self.train_ratio-self.val_ratio)*100:.0f}%)\")\n",
        "        \n",
        "        return train_files, val_files, test_files\n",
        "\n",
        "# Initialize dataset preparation\n",
        "data_prep = MSDDatasetPreparation(data_root=DATA_ROOT, train_ratio=0.7, val_ratio=0.15)\n",
        "data_dicts, dataset_info = data_prep.prepare_data_dicts()\n",
        "train_files, val_files, test_files = data_prep.split_dataset(data_dicts)\n",
        "\n",
        "# Display dataset information\n",
        "print(f\"\\nDataset: {dataset_info['name']}\")\n",
        "print(f\"Modalities: {dataset_info['modality']}\")\n",
        "print(f\"Labels: {dataset_info['labels']}\")\n",
        "print(f\"Total training samples: {dataset_info['numTraining']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93e69d81",
      "metadata": {},
      "source": [
        "## 3. Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23294b3e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set dataset paths\n",
        "DATA_ROOT = \"/content/drive/MyDrive/BrainTumor/Task01_BrainTumour\"\n",
        "SAVE_DIR = \"/content/drive/MyDrive/BrainTumor/models\"\n",
        "\n",
        "# Create save directory if it doesn't exist\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"üìÅ Checking dataset paths...\")\n",
        "print(f\"Data root: {DATA_ROOT}\")\n",
        "print(f\"Save directory: {SAVE_DIR}\")\n",
        "print()\n",
        "\n",
        "# Verify dataset exists\n",
        "if os.path.exists(DATA_ROOT):\n",
        "    print(f\"‚úÖ Dataset root exists\")\n",
        "    \n",
        "    # Check for required folders and files\n",
        "    imagesTr_path = os.path.join(DATA_ROOT, \"imagesTr\")\n",
        "    labelsTr_path = os.path.join(DATA_ROOT, \"labelsTr\")\n",
        "    dataset_json_path = os.path.join(DATA_ROOT, \"dataset.json\")\n",
        "    \n",
        "    print(f\"   - imagesTr folder: {'‚úÖ Found' if os.path.isdir(imagesTr_path) else '‚ùå Missing'}\")\n",
        "    print(f\"   - labelsTr folder: {'‚úÖ Found' if os.path.isdir(labelsTr_path) else '‚ùå Missing'}\")\n",
        "    print(f\"   - dataset.json: {'‚úÖ Found' if os.path.isfile(dataset_json_path) else '‚ùå Missing'}\")\n",
        "    \n",
        "    if os.path.isdir(imagesTr_path):\n",
        "        num_images = len([f for f in os.listdir(imagesTr_path) if f.endswith('.nii.gz') or f.endswith('.nii')])\n",
        "        print(f\"   - Number of images: {num_images}\")\n",
        "    \n",
        "    if os.path.isdir(labelsTr_path):\n",
        "        num_labels = len([f for f in os.listdir(labelsTr_path) if f.endswith('.nii.gz') or f.endswith('.nii')])\n",
        "        print(f\"   - Number of labels: {num_labels}\")\n",
        "else:\n",
        "    print(f\"‚ùå Dataset root NOT found!\")\n",
        "    print()\n",
        "    print(\"üîç Searching for possible locations...\")\n",
        "    \n",
        "    # Search for possible dataset locations\n",
        "    search_paths = [\n",
        "        \"/content/drive/MyDrive/BrainTumor\",\n",
        "        \"/content/drive/MyDrive\",\n",
        "        \"/content/drive/My Drive/BrainTumor\",\n",
        "        \"/content/drive/My Drive\"\n",
        "    ]\n",
        "    \n",
        "    for search_path in search_paths:\n",
        "        if os.path.exists(search_path):\n",
        "            print(f\"\\nüìÇ Found: {search_path}\")\n",
        "            items = os.listdir(search_path)\n",
        "            print(f\"   Contents: {items[:10]}\")  # Show first 10 items\n",
        "            \n",
        "            # Look for Task01 folder\n",
        "            for item in items:\n",
        "                if 'task01' in item.lower() or 'brain' in item.lower():\n",
        "                    print(f\"   ‚≠ê Possible dataset: {os.path.join(search_path, item)}\")\n",
        "    \n",
        "    print()\n",
        "    print(\"üí° Please update DATA_ROOT to the correct path where your dataset is located.\")\n",
        "    print(\"   Your dataset should contain: imagesTr/, labelsTr/, and dataset.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7ac5430",
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Check if already mounted\n",
        "if not os.path.exists('/content/drive/MyDrive'):\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"‚úÖ Google Drive mounted successfully\")\n",
        "else:\n",
        "    print(\"‚úÖ Google Drive already mounted\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a20cb4f5",
      "metadata": {},
      "source": [
        "## 2. Mount Google Drive & Setup Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0e6a569",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import all required libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import monai\n",
        "from monai.data import CacheDataset, DataLoader as MonaiDataLoader\n",
        "from monai.transforms import (\n",
        "    Compose, LoadImaged, EnsureChannelFirstd, Spacingd,\n",
        "    Orientationd, CropForegroundd, ResizeWithPadOrCropd,\n",
        "    NormalizeIntensityd, RandRotate90d, RandFlipd,\n",
        "    RandScaleIntensityd, RandShiftIntensityd, RandAffined\n",
        ")\n",
        "from monai.losses import DiceCELoss, DiceLoss\n",
        "from monai.metrics import DiceMetric\n",
        "from monai.networks.nets import UNet\n",
        "from monai.inferers import sliding_window_inference\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import nibabel as nib\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "monai.utils.set_determinism(seed=42)\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"MONAI version: {monai.__version__}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "329e579c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install monai[all]\n",
        "!pip install nibabel\n",
        "!pip install SimpleITK\n",
        "!pip install matplotlib seaborn\n",
        "!pip install tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55a56f6a",
      "metadata": {},
      "source": [
        "## 1. Setup & Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38499a7f",
      "metadata": {},
      "source": [
        "# Brain Tumor Segmentation - Complete Pipeline\n",
        "## MSD Task01_BrainTumour | 3D U-Net + MedSAM | MONAI + PyTorch\n",
        "\n",
        "This notebook implements a complete brain tumor segmentation pipeline with:\n",
        "- **Dataset**: MSD Task01_BrainTumour (BraTS)\n",
        "- **Models**: 3D U-Net (MONAI) + MedSAM fine-tuning\n",
        "- **Metrics**: Dice Score for Whole Tumor (WT), Tumor Core (TC), Enhancing Tumor (ET)\n",
        "- **Analysis**: Training curves, failure analysis, experiment tracking\n",
        "\n",
        "### Workflow:\n",
        "1. Setup & Installation\n",
        "2. Dataset Preparation\n",
        "3. Preprocessing Transforms\n",
        "4. DataLoaders\n",
        "5. Model Architecture\n",
        "6. Loss Functions\n",
        "7. Training Loop\n",
        "8. Evaluation\n",
        "9. MedSAM Fine-tuning\n",
        "10. Failure Analysis & Visualization"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
